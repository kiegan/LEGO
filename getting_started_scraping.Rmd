---
title: "Getting Started with Scraping"
author: "Kiegan Rice"
date: "June 3, 2017"
output: html_document
---

### Can we find the links to different 'Sets' Home pages on LEGO.com?  


```{r}
#install.packages("rvest")
library(rvest)

url <- "https://www.lego.com/en-us/products"
# url2 <- "https://brickset.com/browse/sets"
html <- read_html(url)
theme_links <- html %>% html_nodes("a") %>% html_attr(name = "href")
# html_text() - will give the text inside the nodes.  
# the a is for the common reference, the href if for all linkts after this 
theme_links
```

This gives us a bunch of extra links that we don't need - we will deal with removing these later. For now, we can just pick one and investigate further. 

### Great! Now, for a specific group of sets, can we get links to each of the individual set pages?  

We will use 'City' as an example.
```{r}
theme_url <- theme_links[19]
prod_url <- paste0(theme_url, "/products")

html_prod <- read_html(prod_url)
html_prod %>% html_nodes("a") %>% html_attr(name = "href")

```

So this gives us a list of all the links! We only want the ones that come after "/products/" and have one of the product ID numbers associated with them. More on this in the future..  


```{r}

crooks_link <- "https://www.lego.com/en-us/city/products/crooks-island-60131"

html_crook <- read_html(crooks_link)
crooks_link <- html_crook %>% html_nodes(".shop-button") %>% html_attr(name = "href") 
crooks_link <- crooks_link[1]

html_crook_page <- read_html(crooks_link)
html_crook_page %>% html_nodes("p , .product-details__product-code, .product-details__ages, .product-price__sale span") %>% html_text()
 
```
